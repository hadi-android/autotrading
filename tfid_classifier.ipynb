{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from yahoo_historical import Fetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Read the Nasdaq (QQQ) index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'QQQ'\n",
    "start = [2019,1,1]\n",
    "\n",
    "df = Fetcher(ticker, start).getHistorical()\t\n",
    "#df = df[['Date','Close']]\n",
    "df.Date = pd.to_datetime(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>150.990005</td>\n",
       "      <td>155.750000</td>\n",
       "      <td>150.880005</td>\n",
       "      <td>154.880005</td>\n",
       "      <td>153.021332</td>\n",
       "      <td>58576700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>152.600006</td>\n",
       "      <td>153.259995</td>\n",
       "      <td>149.490005</td>\n",
       "      <td>149.820007</td>\n",
       "      <td>148.022064</td>\n",
       "      <td>74820200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>152.339996</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>151.740005</td>\n",
       "      <td>156.229996</td>\n",
       "      <td>154.355118</td>\n",
       "      <td>74709300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>156.619995</td>\n",
       "      <td>158.860001</td>\n",
       "      <td>156.110001</td>\n",
       "      <td>158.089996</td>\n",
       "      <td>156.192795</td>\n",
       "      <td>52059300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>159.539993</td>\n",
       "      <td>160.110001</td>\n",
       "      <td>157.199997</td>\n",
       "      <td>159.520004</td>\n",
       "      <td>157.605637</td>\n",
       "      <td>49388700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close   Adj Close  \\\n",
       "0 2019-01-02  150.990005  155.750000  150.880005  154.880005  153.021332   \n",
       "1 2019-01-03  152.600006  153.259995  149.490005  149.820007  148.022064   \n",
       "2 2019-01-04  152.339996  157.000000  151.740005  156.229996  154.355118   \n",
       "3 2019-01-07  156.619995  158.860001  156.110001  158.089996  156.192795   \n",
       "4 2019-01-08  159.539993  160.110001  157.199997  159.520004  157.605637   \n",
       "\n",
       "     Volume  \n",
       "0  58576700  \n",
       "1  74820200  \n",
       "2  74709300  \n",
       "3  52059300  \n",
       "4  49388700  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> create session gain/loss label for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>gain_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>152.600006</td>\n",
       "      <td>153.259995</td>\n",
       "      <td>149.490005</td>\n",
       "      <td>149.820007</td>\n",
       "      <td>148.022064</td>\n",
       "      <td>74820200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>152.339996</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>151.740005</td>\n",
       "      <td>156.229996</td>\n",
       "      <td>154.355118</td>\n",
       "      <td>74709300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>156.619995</td>\n",
       "      <td>158.860001</td>\n",
       "      <td>156.110001</td>\n",
       "      <td>158.089996</td>\n",
       "      <td>156.192795</td>\n",
       "      <td>52059300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>159.539993</td>\n",
       "      <td>160.110001</td>\n",
       "      <td>157.199997</td>\n",
       "      <td>159.520004</td>\n",
       "      <td>157.605637</td>\n",
       "      <td>49388700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>160.139999</td>\n",
       "      <td>161.520004</td>\n",
       "      <td>159.470001</td>\n",
       "      <td>160.820007</td>\n",
       "      <td>158.890045</td>\n",
       "      <td>46491700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>159.600006</td>\n",
       "      <td>161.369995</td>\n",
       "      <td>158.699997</td>\n",
       "      <td>161.279999</td>\n",
       "      <td>159.344513</td>\n",
       "      <td>38943400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>160.330002</td>\n",
       "      <td>160.860001</td>\n",
       "      <td>159.789993</td>\n",
       "      <td>160.690002</td>\n",
       "      <td>158.761581</td>\n",
       "      <td>30176600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Open        High         Low       Close   Adj Close  \\\n",
       "1 2019-01-03  152.600006  153.259995  149.490005  149.820007  148.022064   \n",
       "2 2019-01-04  152.339996  157.000000  151.740005  156.229996  154.355118   \n",
       "3 2019-01-07  156.619995  158.860001  156.110001  158.089996  156.192795   \n",
       "4 2019-01-08  159.539993  160.110001  157.199997  159.520004  157.605637   \n",
       "5 2019-01-09  160.139999  161.520004  159.470001  160.820007  158.890045   \n",
       "6 2019-01-10  159.600006  161.369995  158.699997  161.279999  159.344513   \n",
       "7 2019-01-11  160.330002  160.860001  159.789993  160.690002  158.761581   \n",
       "\n",
       "     Volume  gain_loss  \n",
       "1  74820200          0  \n",
       "2  74709300          1  \n",
       "3  52059300          1  \n",
       "4  49388700          1  \n",
       "5  46491700          1  \n",
       "6  38943400          1  \n",
       "7  30176600          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change = df.Close-df.Close.shift(1)\n",
    "change.head()\n",
    "df['gain_loss'] = change>0\n",
    "df.gain_loss = df.gain_loss.astype(int)\n",
    "df=df.iloc[1:,]\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from searchtweets import load_credentials, gen_rule_payload, collect_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "rootdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Read stock market news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock_market_2019-03-01-2019-03-30.sav\n",
      "stock_market_2019-04-01-2019-04-29.sav\n",
      "stock_market_2019-05-01-2019-05-31.sav\n",
      "stock_market_2019-06-01-2019-06-28.sav\n",
      "stock_market_2019-07-01-2019-07-31.sav\n",
      "stock_market_2019-08-01-2019-08-30.sav\n",
      "stock_market_2019-09-01-2019-09-30.sav\n",
      "stock_market_2019-10-01-2019-10-31.sav\n",
      "stock_market_2019-11-01-2019-11-22.sav\n",
      "stock_market_2019-11-25-2019-12-30.sav\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e20379b01fe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mall_tweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "all_tweets=[]\n",
    "regex = re.compile('stock_market.*\\.sav')\n",
    "#'Run.*\\.py$'\n",
    "\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "  for file in files:\n",
    "    if regex.match(file):\n",
    "        all_tweets.append(pickle.load(open(file,'rb')))\n",
    "        print(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[]\n",
    "dates=[]\n",
    "names=[]\n",
    "for i in range(len(all_tweets)):\n",
    "    text.append([tweet.all_text for tweet in all_tweets[i]])\n",
    "    dates.append([tweet.created_at_datetime for tweet in all_tweets[i]])\n",
    "    names.append([tweet.name for tweet in all_tweets[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text1 = [item for sublist in text for item in sublist]\n",
    "news = pd.DataFrame(text1, columns={'text'})\n",
    "news['Date'] = [item for sublist in dates for item in sublist]\n",
    "news['name'] = [item for sublist in names for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.to_csv('stock_market_news.cav',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.Date = pd.to_datetime(news.Date)\n",
    "news.Date = [a-timedelta(hours=4) for a in news.Date]\n",
    "news = news.sort_values('Date').reset_index(drop=True)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsh=news.Date.astype('str')\n",
    "#print(d)\n",
    "newsh = [d[d.find(':')-2:d.find(':')] for d in newsh]\n",
    "news['hour'] = newsh\n",
    "news.hour = news.hour.astype(int)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Remove news tweeted after 12 pm so that late news is not included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news[news.hour<=12].shape)\n",
    "print(news[(news.hour<=12) & (news.hour>=8)].shape)\n",
    "news1 = news[(news.hour<=12) & (news.hour>=8)]\n",
    "print(news1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "news1.Date = pd.to_datetime(news1['Date']).dt.floor('d')\n",
    "news1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Merge stock market news dataset with stock price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(news1, on = 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Remove URLs and usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_words = [list(filter(lambda word: word[0]!='@', text.split())) for text in df.text]\n",
    "drop_words = [list(filter(lambda word: word[0:4]!='http', text)) for text in drop_words]\n",
    "drop_words = [' '.join(a) for a in drop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = drop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> remove English stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "newStopWords = ['this']\n",
    "stopwords.extend(newStopWords)\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "  \n",
    "stop_words = set(stopwords) \n",
    "  \n",
    "word_tokens = word_tokenize(example_sent.lower()) \n",
    "\n",
    "filtered_sentence = [list(filter(lambda word: word not in stop_words, text.split())) for text in df.text]\n",
    "filtered_sentence = [' '.join(a) for a in filtered_sentence]\n",
    "filtered_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text=filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create TFID Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)    \n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = count_vect.get_feature_names()\n",
    " \n",
    "#get tfidf vector for first document\n",
    "#first_document_vector=X_train_tfidf[0]\n",
    "first_document_vector=X_train_tfidf[0]\n",
    "\n",
    "#print the scores\n",
    "ft = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "ft=ft.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "ft.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "#X = vectorizer.fit_transform(df.text)\n",
    "#print(vectorizer.get_feature_names())\n",
    "processed_features = vectorizer.fit_transform(df.text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = df.gain_loss\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Train classifier to predict stock price based on TFID vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train,predictions))\n",
    "print(accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
